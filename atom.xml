<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>artanis home</title>
  
  <subtitle>just keep going</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-03-10T11:06:33.814Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Artanis</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Evaluation Standard</title>
    <link href="http://yoursite.com/2018/03/10/Evaluation-Standard/"/>
    <id>http://yoursite.com/2018/03/10/Evaluation-Standard/</id>
    <published>2018-03-10T11:01:50.000Z</published>
    <updated>2018-03-10T11:06:33.814Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Evaluation-Standard"><a href="#Evaluation-Standard" class="headerlink" title="Evaluation Standard"></a>Evaluation Standard</h1><h3 id="Accurency-Precision-Recall-F1-ROC-AUC"><a href="#Accurency-Precision-Recall-F1-ROC-AUC" class="headerlink" title="Accurency/Precision/Recall/F1/ROC/AUC"></a>Accurency/Precision/Recall/F1/ROC/AUC</h3><h2 id="Accurency"><a href="#Accurency" class="headerlink" title="Accurency"></a>Accurency</h2><p>accurency = right / all (right: the instance you predict right, all； all sample)</p><h2 id="Precision-and-Recall-and-F1"><a href="#Precision-and-Recall-and-F1" class="headerlink" title="Precision and Recall and F1"></a>Precision and Recall and F1</h2><h3 id="1-confusion-matrix"><a href="#1-confusion-matrix" class="headerlink" title="1. confusion matrix"></a>1. confusion matrix</h3><p>TP: true positive   FN: false negative</p><p>FP: false positive   TP: True negative</p><h3 id="2-Precision"><a href="#2-Precision" class="headerlink" title="2. Precision"></a>2. Precision</h3><p>P = TP/(TP + FP)</p><p>It refers to the accurency rate of you prediction</p><h3 id="3-Recall"><a href="#3-Recall" class="headerlink" title="3. Recall"></a>3. Recall</h3><p>R = TP/(TP + FN)</p><p>It refers to the comprehensive rate of your prediction</p><h3 id="4-Precision-and-Recall’s-description"><a href="#4-Precision-and-Recall’s-description" class="headerlink" title="4. Precision and Recall’s description"></a>4. Precision and Recall’s description</h3><p>The Precision and Recall are often in conflict with each other, so if one P-R curve is completely wrapped by another, then we can assume that the latter is better.</p><h3 id="5-F1"><a href="#5-F1" class="headerlink" title="5. F1"></a>5. F1</h3><p>F1 is the harmonic mean of the precision and recall</p><p>definition: F1 = (2 <em> P </em> R)/(P + R)</p><p>If we want to give a weight to the each evaluation method, then we can use the β like this</p><p>F1 = (1 + β^2) <em> P </em> R/((β^2 * P) + B)</p><h3 id="6-extension-and-application"><a href="#6-extension-and-application" class="headerlink" title="6. extension and application"></a>6. extension and application</h3><p>Sometimes we some other situation:</p><ul><li>have trained and tested quite a few times and we get severial confusion matrix  </li><li>have trained and tested in different datasets, hoping to evaluate the algorithm as a whole</li><li>for Multi-category tasks, we combine each two category into a confusion matrix</li></ul><p>one method:</p><p>calculate each Precision and Recall in different confusion matrix and then calculate the mean of them(called macro-P, macro-R and macro-F1)</p><p>macro-P = 1/n <em> ∑P<br>macro-R = 1/n </em> ∑R<br>macro-F1 = (2 <em> macro-P </em> macro-R)/(macro-P + macro-R)</p><p>another method:</p><p>calculate the mean of TP, FP, FN, TN, then calculate the micro-P, micro-R and micro-F1</p><h2 id="ROC-and-AUC"><a href="#ROC-and-AUC" class="headerlink" title="ROC and AUC"></a>ROC and AUC</h2><p>So many learning model generate a value or probablity prediction and then compare it with the threshold. Then we cansort the value and get a cut point and divide the sample into two part. So the quality of sorting represent the ability of generalization, anfd we can use the ROC curve</p><p><img src="ROC.png" alt=""></p><p>If we assume that one marker is (x, y), then if the next sample is the true positive, then the coordinate of it is (x, y + 1/m+), and if it is false positive, then the coordinate of it is (x + 1/m-, y)</p><p>Just like above, if one learning model’s ROC curve is wrapped by the another, then the latter is better. Another method to measure is to compare the <em>Areas Under the ROC Curve</em>(<strong>AUC</strong>)</p><p>defintion: AUC = 1/2 ∑(xi+1 - xi) <em> (yi + yi+1)   </em>i from 1 to m-1*</p><p>AUC is the evaluationof the quality of prediction sorting, if we have m+ positive example and m- negative example, and D+ and D- represent positive and negative set, then we can define loss as:</p><p>lrank = 1/m+ <em> m- ∑ ∑ (II(f(x+) &lt; f(x-)) + 1/2 </em> II(f(x+) = f(x-)))</p><p>This means that if the positive prediction value is smaller than the negative, then you are punished by one point, the same as another. We can find that AUC = 1 - lrank</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Evaluation-Standard&quot;&gt;&lt;a href=&quot;#Evaluation-Standard&quot; class=&quot;headerlink&quot; title=&quot;Evaluation Standard&quot;&gt;&lt;/a&gt;Evaluation Standard&lt;/h1&gt;&lt;h3 i
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>读资本论</title>
    <link href="http://yoursite.com/2018/03/06/%E8%AF%BB%E8%B5%84%E6%9C%AC%E8%AE%BA/"/>
    <id>http://yoursite.com/2018/03/06/读资本论/</id>
    <published>2018-03-05T23:15:31.000Z</published>
    <updated>2018-03-05T23:18:26.603Z</updated>
    
    <content type="html"><![CDATA[<p>百忙之中偶有余闲，决定读一读《资本论》，权当兴趣使然。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;百忙之中偶有余闲，决定读一读《资本论》，权当兴趣使然。&lt;/p&gt;

      
    
    </summary>
    
      <category term="life" scheme="http://yoursite.com/categories/life/"/>
    
    
      <category term="经济" scheme="http://yoursite.com/tags/%E7%BB%8F%E6%B5%8E/"/>
    
  </entry>
  
  <entry>
    <title>Faster RCNN 详解与实现</title>
    <link href="http://yoursite.com/2018/02/26/Faster-RCNN-%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/"/>
    <id>http://yoursite.com/2018/02/26/Faster-RCNN-详解与实现/</id>
    <published>2018-02-25T16:54:50.000Z</published>
    <updated>2018-03-05T23:09:48.029Z</updated>
    
    <content type="html"><![CDATA[<p>最近一直在研究CV领域的一些算法，由于本人编程水平较弱加之faster rcnn算法比较复杂，虽然原理在很早就大致看懂，但在看源码的时候仍然吃了不少苦头，近些时候，终于了解了代码的大致含义并借鉴大神们的代码自己用pytorch实现了一下。在此，想跟大家详细地解释一下代码的含义， 帮助读者更好的理解这一算法。本人代码如下：</p><p><a href="https://github.com/starcraft2chunjie/Faster-RCNN-pytorch/tree/master" target="_blank" rel="noopener">Faster-RCNN-pytorch</a></p><p>需要先了解一下faster rcnn的读者可以点击以下链接，这是本人看到的比较全面细致的faster rcnn教程。</p><p><a href="https://www.jianshu.com/p/de37451a0a77?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation" target="_blank" rel="noopener">Faster RCNN 详解</a></p><h2 id="model"><a href="#model" class="headerlink" title="model"></a>model</h2><p>这一部分对应model_easy.py，我们知道, Faster RCNN 总共实际上就是四个模型，CNN模型， RPN(Region proposal layer), ROI Pooling layer, Classification layer(可以称为Faster RCNN层)。CNN层使用预训练的vgg16提取特征，得到feature map，然后进入RPN层, RPN层s首先经过一个kernel_size为3的层,之后再分为两部分，分别输出2<em>9大小和4</em>9大小的向量（对应于9 anchor <em> 2 classifier以及 9 anchor </em> 4 coordinate）,通过训练修正proposal的位置以及数量（通过rpn文件里面的proposal_layer.py），修正好的proposal进入ROI Pooling层统一划成7*7大小，最后进入FasterRCNN层输出最后的bbox_pred(bbox_delta)以及scores。</p><p>CNN层比较简单，在这里不再赘述。我们看一看RPN层的源码。</p><h3 id="RPN"><a href="#RPN" class="headerlink" title="RPN"></a>RPN</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"># the simple model of RPN</span><br><span class="line">class RPN(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(RPN, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.conv = nn.Sequential(nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=(1, 1)),</span><br><span class="line">                                            nn.ReLU())</span><br><span class="line"></span><br><span class="line">        # 9 anchor * 2 classfier (object or non-object) each grid</span><br><span class="line">        self.conv1 = nn.Conv2d(512, 2 * 9, kernel_size=1, stride=1)</span><br><span class="line"></span><br><span class="line">        # 9 anchor * 4 coordinate regressor each grids</span><br><span class="line">        self.conv2 = nn.Conv2d(512, 4 * 9, kernel_size=1, stride=1)</span><br><span class="line">        self.softmax = nn.Softmax()</span><br><span class="line"></span><br><span class="line">    def forward(self, features):</span><br><span class="line"></span><br><span class="line">        features = self.conv(features)</span><br><span class="line"></span><br><span class="line">        logits, rpn_bbox_pred = self.conv1(features), self.conv2(features)</span><br><span class="line"></span><br><span class="line">        height, width = features.size()[-2:]</span><br><span class="line">        logits = logits.squeeze(0).permute(1, 2, 0).contiguous()  # (1, 18, H/16, W/16) =&gt; (H/16 ,W/16, 18)</span><br><span class="line">        logits = logits.view(-1, 2)  # (H/16 ,W/16, 18) =&gt; (H/16 * W/16 * 9, 2)</span><br><span class="line"></span><br><span class="line">        rpn_cls_prob = self.softmax(logits)</span><br><span class="line">        rpn_cls_prob = rpn_cls_prob.view(height, width, 18)  # (H/16 * W/16 * 9, 2)  =&gt; (H/16 ,W/16, 18)</span><br><span class="line">        rpn_cls_prob = rpn_cls_prob.permute(2, 0, 1).contiguous().unsqueeze(0) # (H/16 ,W/16, 18) =&gt; (1, 18, H/16, W/16)</span><br><span class="line"></span><br><span class="line">        return rpn_bbox_pred, rpn_cls_prob, logits</span><br></pre></td></tr></table></figure><p>注意forward的返回值，一个是rpn_bbox_pred，这个是我们我提到的教程里面的预测的[dx, dy, dh, dw]，也是之后的bbox_delta。rpn_cls_prob也仅仅只是logits经过了一层softmax函数而已。模型大致架构比较简单，下面来看看与RPN层相关的函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">def proposal(self, rpn_bbox_pred, rpn_cls_prob, im_info, test, args):</span><br><span class="line">       &quot;&quot;&quot;</span><br><span class="line">       Arguments:</span><br><span class="line">           rpn_bbox_pred (Tensor) : (1, 4*9, H/16, W/16)</span><br><span class="line">           rpn_cls_prob (Tensor) : (1, 2*9, H/16, W/16)</span><br><span class="line">           im_info (Tuple) : (Height, Width, Channel, scale_ratios)</span><br><span class="line">           test (Bool) : True or False</span><br><span class="line">           args (argparse.Namespace) : global arguments</span><br><span class="line">       Return:</span><br><span class="line">           # in each minibatch number of proposal boxes is variable</span><br><span class="line">           proposals_boxes (Ndarray) : ( # proposal boxes, 4)</span><br><span class="line">           scores (Ndarray) :  ( # proposal boxes, )</span><br><span class="line">       &quot;&quot;&quot;</span><br><span class="line">       &quot;&quot;&quot;</span><br><span class="line">       # Algorithm:</span><br><span class="line">       #</span><br><span class="line">       # for each (H, W) location i</span><br><span class="line">       #   generate A anchor boxes centered on cell i</span><br><span class="line">       #   apply predicted bbox deltas at cell i to each of the A anchors</span><br><span class="line">       # clip predicted boxes to image</span><br><span class="line">       # remove predicted boxes with either height or width &lt; threshold</span><br><span class="line">       # sort all (proposal, score) pairs by score from highest to lowest</span><br><span class="line">       # take top pre_nms_topN proposals before NMS</span><br><span class="line">       # apply NMS with threshold 0.7 to remaining proposals</span><br><span class="line">       # take after_nms_topN proposals after NMS</span><br><span class="line">       # return the top proposals (-&gt; RoIs top, scores top)</span><br><span class="line">       #layer_params = yaml.load(self.param_str_)</span><br><span class="line">       &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       anchors = generate_anchors()</span><br><span class="line">       _num_anchors = anchors.shape[0]</span><br><span class="line"></span><br><span class="line">       all_anchors = get_anchor(rpn_cls_prob, anchors)   # [H * W * 9, 4]</span><br><span class="line"></span><br><span class="line">       pre_nms_topn = args.pre_nms_topn if test == False else args.test_pre_nms_topn</span><br><span class="line">       nms_thresh = args.nms_thresh if test == False else args.test_nms_thresh</span><br><span class="line">       post_nms_topn = args.post_nms_topn if test == False else args.test_post_nms_topn</span><br><span class="line"></span><br><span class="line">       &quot;&quot;&quot;It&apos;s directly from anchor_target_layer, essentially from training the RPN&quot;&quot;&quot;</span><br><span class="line">       bbox_deltas = self._get_bbox_deltas(rpn_bbox_pred).data.cpu().numpy()</span><br><span class="line"></span><br><span class="line">       # 1. Convert anchors into proposal via bbox transformation</span><br><span class="line">       &quot;&quot;&quot;Here we need to generate the precise proposal location for the later operation&quot;&quot;&quot;</span><br><span class="line">       proposals_boxes = bbox_transform_inv(all_anchors, bbox_deltas)  # (H/16 * W/16 * 9, 4) all proposal boxes</span><br><span class="line">       scores = self._get_pos_score(rpn_cls_prob).data.cpu().numpy()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       # 2. clip predicted boxes to image</span><br><span class="line">       proposals = clip_boxes(proposals_boxes, im_info[:2])</span><br><span class="line"></span><br><span class="line">        # 3. remove predicted boxes with either height or width &lt; threshold</span><br><span class="line">       # (NOTE: convert min_size to input image scale stored in im_info[3])</span><br><span class="line">       keep = filter_boxes(proposals_boxes, self.args.min_size * max(im_info[3]))</span><br><span class="line">       proposals = proposals[keep, :]</span><br><span class="line">       scores = scores[keep]</span><br><span class="line"></span><br><span class="line">       # 4. sort all (proposal, score) pairs by score from highest to lowest</span><br><span class="line">       # 5. take top pre_nms_topn (e.g. 6000)</span><br><span class="line">       order = scores.ravel().argsort()[::-1]</span><br><span class="line">       if pre_nms_topn &gt; 0:</span><br><span class="line">           order = order[:pre_nms_topn]</span><br><span class="line">       proposals = proposals[order, :]</span><br><span class="line">       scores = scores[order]</span><br><span class="line"></span><br><span class="line">       # 6. apply nms (e.g. threshold = 0.7)</span><br><span class="line"></span><br><span class="line">       keep = py_cpu_nms(np.hstack((proposals, scores)), nms_thresh)</span><br><span class="line"></span><br><span class="line">       # 7. take after_nms_topN (e.g. 300)</span><br><span class="line">       if post_nms_topn &gt; 0:</span><br><span class="line">           keep = keep[:post_nms_topn]</span><br><span class="line">       </span><br><span class="line">       # 8. return the top proposals (-&gt; RoIs top)</span><br><span class="line">       proposals = proposals[keep, :]</span><br><span class="line">       scores = scores[keep]</span><br><span class="line">       batch_inds = np.zeros((proposals.shape[0], 1), dtype=np.float32)</span><br><span class="line">       blob = np.hstack((batch_inds, proposals.astype(np.float32, copy = False)))</span><br><span class="line">       return blob</span><br></pre></td></tr></table></figure><p>这段代码的作用是什么？用教程里面的话就是：</p><blockquote><ol><li>生成anchors，利用[dx(A)，dy(A)，dw(A)，dh(A)]对所有的anchors做bbox regression回归（这里的anchors生成和训练时完全一致）</li></ol></blockquote><blockquote><ol><li>按照输入的foreground softmax scores由大到小排序anchors，提取前pre_nms_topN(e.g. 6000)个anchors，即提取修正位置后的foreground anchors。</li></ol></blockquote><blockquote><ol><li>利用im_info将fg anchors从MxN尺度映射回PxQ原图，判断fg anchors是否大范围超过边界，剔除严重超出边界fg anchors。</li></ol></blockquote><blockquote><ol><li>进行nms（nonmaximum suppression，非极大值抑制）</li></ol></blockquote><blockquote><ol><li>再次按照nms后的foreground softmax scores由大到小排序fg anchors，提取前post_nms_topN(e.g. 300)结果作为proposal输出。</li></ol></blockquote><blockquote><ol><li>之后输出proposal=[x1, y1, x2, y2]，注意，由于在第三步中将anchors映射回原图判断是否超出边界，所以这里输出的proposal是对应MxN输入图像尺度的</li></ol></blockquote><p>简单来说，就是对产生的所有anchor进行修正以及筛选。此函数输入的主要参数是之前RPN网络输出的rpn_bbox_pred以及rpn_cls_prob。这里有几行代码需要解释一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bbox_deltas = self._get_bbox_deltas(rpn_bbox_pred).data.cpu().numpy()</span><br><span class="line"></span><br><span class="line">proposals_boxes = bbox_transform_inv(all_anchors, bbox_deltas)  # (H/16 * W/16 * 9, 4) all proposal boxes</span><br><span class="line"></span><br><span class="line">scores = self._get_pos_score(rpn_cls_prob).data.cpu().numpy()</span><br></pre></td></tr></table></figure><p>_get_bbox_deltas仅仅是把rpn_bbox_pred转换为了（H/16 <em> W/16 </em> 9, 4）, bbox_transform_inv则是根据bbox_deltas以及anchors生成了对应的pred_anchor(注意之前的rpn_bbox_pred仅仅是生成的[dx, dy, dh, dw]，不是最终确定的proposal)，_get_pos_score也仅仅是将rpn_cls_score转化为(H/16 <em> W/16 </em> 9, 1)</p><h3 id="ROI-Pooling"><a href="#ROI-Pooling" class="headerlink" title="ROI Pooling"></a>ROI Pooling</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">class ROIpooling(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, size=(7, 7), spatial_scale=1.0 / 16.0):</span><br><span class="line">        super(ROIpooling, self).__init__()</span><br><span class="line">        self.adapmax2d = nn.AdaptiveMaxPool2d(size)</span><br><span class="line">        self.spatial_scale = spatial_scale</span><br><span class="line"></span><br><span class="line">    def forward(self, features, rois_boxes):</span><br><span class="line"></span><br><span class="line">        # rois_boxes : [x, y, x`, y`]</span><br><span class="line"></span><br><span class="line">        if type(rois_boxes) == np.ndarray:</span><br><span class="line">            rois_boxes = to_var(torch.from_numpy(rois_boxes))</span><br><span class="line"></span><br><span class="line">        rois_boxes = rois_boxes.data.float().clone()</span><br><span class="line">        rois_boxes.mul_(self.spatial_scale)</span><br><span class="line">        rois_boxes = rois_boxes.long()</span><br><span class="line"></span><br><span class="line">        output = []</span><br><span class="line"></span><br><span class="line">        for i in range(rois_boxes.size(0)):</span><br><span class="line">            roi = rois_boxes[i]</span><br><span class="line"></span><br><span class="line">            try:</span><br><span class="line"></span><br><span class="line">                roi_feature = features[:, :, roi[1]:(roi[3] + 1), roi[0]:(roi[2] + 1)]</span><br><span class="line">            except Exception as e:</span><br><span class="line">                print(e, roi)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            pool_feature = self.adapmax2d(roi_feature)</span><br><span class="line">            output.append(pool_feature)</span><br><span class="line"></span><br><span class="line">        return torch.cat(output, 0)</span><br></pre></td></tr></table></figure><p>ROI Pooling显得比较简单，但这并不是因为其算法本身简单，实际上，此层需要实现的算法是对任意输入的proposal，都要加工成7*7大小，这个工作量似乎不小，实际上，之前大神的代码里，ROI Pooling的实现代码很长，但正因为如此，pytorch的contributor将其封装，现在仅仅只需要调用adapmax2d就可以了。</p><h3 id="FasterRCNN"><a href="#FasterRCNN" class="headerlink" title="FasterRCNN"></a>FasterRCNN</h3><p>这个代码比较简单，没什么好讲的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">class FasterRcnn(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(FasterRcnn, self).__init__()</span><br><span class="line">        self.fc1 = nn.Sequential(nn.Linear(512 * 7 * 7, 4096),</span><br><span class="line">                                 nn.ReLU(),</span><br><span class="line">                                 nn.Dropout())</span><br><span class="line"></span><br><span class="line">        self.fc2 = nn.Sequential(nn.Linear(4096, 4096),</span><br><span class="line">                                 nn.ReLU(),</span><br><span class="line">                                 nn.Dropout())</span><br><span class="line"></span><br><span class="line">        # 20 class + 1 backround classfier each roi</span><br><span class="line">        self.classfier = nn.Linear(4096, 21)</span><br><span class="line">        self.softmax = nn.Softmax()</span><br><span class="line"></span><br><span class="line">        # 21 class * 4 coordinate regressor each roi</span><br><span class="line">        self.regressor = nn.Linear(4096, 21 * 4)</span><br><span class="line"></span><br><span class="line">    def forward(self, features):</span><br><span class="line"></span><br><span class="line">        features = features.view(-1, 512 * 7 * 7)</span><br><span class="line">        features = self.fc1(features)</span><br><span class="line">        features = self.fc2(features)</span><br><span class="line"></span><br><span class="line">        try:</span><br><span class="line">            logits = self.classfier(features)</span><br><span class="line">            scores = self.softmax(logits)</span><br><span class="line">            bbox_delta = self.regressor(features)</span><br><span class="line"></span><br><span class="line">        except Exception as e:</span><br><span class="line">            print(e, logits)</span><br><span class="line"></span><br><span class="line">        return bbox_delta, scores, logits</span><br></pre></td></tr></table></figure><h2 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h2><p>loss部分主要分为两个部分，rpn_loss以及fasterRCNN_loss</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">def rpn_loss(rpn_cls_prob, rpn_logits, rpn_bbox_pred, rpn_labels, rpn_bbox_targets, rpn_bbox_inside_weights):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Arguments:</span><br><span class="line">        rpn_cls_prob (Tensor): (1, 2*9, H/16, W/16)</span><br><span class="line">        rpn_logits (Tensor): (H/16 * W/16 * 9 , 2) object or non-object rpn_logits</span><br><span class="line">        rpn_bbox_pred (Tensor): (1, 4*9, H/16, W/16) predicted boxes</span><br><span class="line">        rpn_labels (Ndarray) : (H/16 * W/16 * 9 ,)</span><br><span class="line">        rpn_bbox_targets (Ndarray) : (H/16 * W/16 * 9, 4)</span><br><span class="line">        rpn_bbox_inside_weights (Ndarray) : (H/16 * W/16 * 9, 4) masking for only positive box loss</span><br><span class="line">    Return:</span><br><span class="line">        cls_loss (Scalar) : classfication loss</span><br><span class="line">        reg_loss * 10 (Scalar) : regression loss</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    height, width = rpn_cls_prob.size()[-2:]  # (H/16, W/16)</span><br><span class="line">    rpn_cls_prob = rpn_cls_prob.squeeze(0).permute(1, 2, 0).contiguous()  # (1, 18, H/16, W/16) =&gt; (H/16 ,W/16, 18)</span><br><span class="line">    rpn_cls_prob = rpn_cls_prob.view(-1, 2)  # (H/16 ,W/16, 18) =&gt; (H/16 * W/16 * 9, 2)</span><br><span class="line"></span><br><span class="line">    rpn_labels = to_tensor(rpn_labels).long() # convert properly # (H/16 * W/16 * 9)</span><br><span class="line"></span><br><span class="line">    #index where not -1</span><br><span class="line">    idx = rpn_labels.ge(0).nonzero()[:, 0]</span><br><span class="line">    rpn_cls_prob = rpn_cls_prob.index_select(0, to_var(idx))</span><br><span class="line">    rpn_labels = rpn_labels.index_select(0, idx)</span><br><span class="line">    rpn_logits = rpn_logits.squeeze().index_select(0, to_var(idx))</span><br><span class="line"></span><br><span class="line">    positive_cnt = torch.sum(rpn_labels.eq(1))</span><br><span class="line">    negative_cnt = torch.sum(rpn_labels.eq(0))</span><br><span class="line"></span><br><span class="line">    rpn_labels = to_var(rpn_labels)</span><br><span class="line"></span><br><span class="line">    cls_crit = nn.CrossEntropyLoss()</span><br><span class="line">    cls_loss = cls_crit(rpn_logits, rpn_labels)</span><br><span class="line"></span><br><span class="line">    rpn_bbox_targets = torch.from_numpy(rpn_bbox_targets)</span><br><span class="line">    rpn_bbox_targets = rpn_bbox_targets.view(height, width, 36)  # (H/16 * W/16 * 9, 4)  =&gt; (H/16 ,W/16, 36)</span><br><span class="line">    rpn_bbox_targets = rpn_bbox_targets.permute(2, 0, 1).contiguous().unsqueeze(0) # (H/16 ,W/16, 36) =&gt; (1, 36, H/16, W/16)</span><br><span class="line">    rpn_bbox_targets = to_var(rpn_bbox_targets)</span><br><span class="line"></span><br><span class="line">    rpn_bbox_inside_weights = torch.from_numpy(rpn_bbox_inside_weights)</span><br><span class="line">    rpn_bbox_inside_weights = rpn_bbox_inside_weights.view(height, width, 36)  # (H/16 * W/16 * 9, 4)  =&gt; (H/16 ,W/16, 36)</span><br><span class="line">    rpn_bbox_inside_weights = rpn_bbox_inside_weights.permute(2, 0, 1).contiguous().unsqueeze(0) # (H/16 ,W/16, 36) =&gt; (1, 36, H/16, W/16)</span><br><span class="line"></span><br><span class="line">    rpn_bbox_inside_weights = rpn_bbox_inside_weights.cuda() if torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line">    rpn_bbox_pred = to_var(torch.mul(rpn_bbox_pred.data, rpn_bbox_inside_weights))</span><br><span class="line">    rpn_bbox_targets = to_var(torch.mul(rpn_bbox_targets.data, rpn_bbox_inside_weights))</span><br><span class="line"></span><br><span class="line">    reg_loss = F.smooth_l1_loss(rpn_bbox_pred, rpn_bbox_targets, size_average = False) / (positive_cnt + 1e-4)</span><br><span class="line"></span><br><span class="line">    return cls_loss, reg_loss * 10</span><br></pre></td></tr></table></figure><p>首先注意一点，rpn_bbox_targets, rpn_bbox_inside_weights这两个参数是从anchor_target此函数得来的。</p><p>rpn_loss的主要操作流程如下：</p><ul><li><p>筛选出label值不是-1的proposal(-1表示don’t care area)</p></li><li><p>计算出是前景的proposal和是背景的proposal的数目。</p></li><li><p>classification使用CrossEntropyLoss(注意CrossEntropyLoss已经包含了log softmaxLoss,所以只需要使用logits作为参数)</p></li><li><p>regression使用smooth_l1_loss</p></li><li><p>综合两个函数</p></li></ul><p>frcnn_loss与之相近，就不再赘述</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近一直在研究CV领域的一些算法，由于本人编程水平较弱加之faster rcnn算法比较复杂，虽然原理在很早就大致看懂，但在看源码的时候仍然吃了不少苦头，近些时候，终于了解了代码的大致含义并借鉴大神们的代码自己用pytorch实现了一下。在此，想跟大家详细地解释一下代码的含
      
    
    </summary>
    
      <category term="technology" scheme="http://yoursite.com/categories/technology/"/>
    
    
      <category term="CV" scheme="http://yoursite.com/tags/CV/"/>
    
  </entry>
  
</feed>
