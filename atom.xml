<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>artanis home</title>
  
  <subtitle>生活像是一场游戏，有人陪伴才最好</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-04-11T15:25:19.432Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Artanis</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Detection之RCNN一族</title>
    <link href="http://yoursite.com/2018/04/08/Detection%E4%B9%8BRCNN%E4%B8%80%E6%97%8F/"/>
    <id>http://yoursite.com/2018/04/08/Detection之RCNN一族/</id>
    <published>2018-04-07T16:18:51.000Z</published>
    <updated>2018-04-11T15:25:19.432Z</updated>
    
    <content type="html"><![CDATA[<p>Detection is an important part of computer vision. Today I will take a view at the prevail algorithm in detection areas, named RCNN and it’s extension. </p><h2 id="RCNN"><a href="#RCNN" class="headerlink" title="RCNN"></a>RCNN</h2><p>RCNN’s meaning is region based CNN. Unlike yolo and yolo9000, RCNN chose the region as the base of it’s predict bounding boxes. Finding that if we just use the location like x, y, then it’s hard to converge, because firsty there maybe exist a couple of objects and then the x, y have difficulty deciding which to approach. secondly, x,y has no limition and can appear in anywhere on the image. So RCNN use prechoosed region and then finetune the bounding boxes, actually compute the scaling and offset. The RCNN’s precess is like this:</p><ul><li>use some methods to generate regions(e.t.c selective search)</li><li>adopt the CNN model to extract the feature.</li><li>put the feature map into the SVM binary classifier.</li><li>put the feature map into the regressor to finetune</li></ul><p>The schemetic diagram is below:<br><img src="" alt=""></p><p>Note that RCNN is puting the every region into the network to train which consume a lot of time. Also note that RCNN had to first wrap resize every region into fixed size because FCN is required fixed-size input. So we will find the image to be a little geometric distortion.</p><p>The training detail is: First we resize the image to 227 * 227, then we pretrain the image on the ILVCR(It has 1000 categories). Next we adopt domain-specific fine-tuning on the PASCAL VOC 2007(21 categories, 20 classes and 1 background). When we test, we put the layer of 4096 dimension into the SVM classifier and likewise we put the layer into the regression to compute the scaling and offset.</p><p>RCNN is the foundation work of image detection using neural network. It still has a lot of drawbacks which will be solved in the next few algorthims.</p><h2 id="SPPnet"><a href="#SPPnet" class="headerlink" title="SPPnet"></a>SPPnet</h2><p>SPPnet add a layer called spatial pyramid pooling layer. The pooling layer is like this:</p><p><img src="Picture5.png" alt=""> </p><p>Suppose we assume that the feature map is H <em> W size. Then we want to put the feature map into 4 </em> 4 so we need to manually regularize the stride to H/4 <em> W/4 and the kernel size of H/4 </em> W/4. Consequnently, the feature map is resized into 4 <em> 4. Likewise, the 2 </em> 2 and 1 * 1 feature map is generated. Then we flat and cluster them into one vector and sent it to the FCN. It plays the role of generate a fix-sized feature map.</p><p>There exist quite a few advantages to use this method. Firstly, RCNN use wrapping to resize the region into fix-size feature map which will cause geometric distortion. And this method will avoid that kind of problem. Moreover, we don’t need to put every region into the network any more. We put the whole image into the network instead. We just need to know where the region is. Depending on this change, the running time is dramatically reduced. </p><h2 id="Fast-RCNN"><a href="#Fast-RCNN" class="headerlink" title="Fast RCNN"></a>Fast RCNN</h2><p>We know that RCNN and SPPnet has Multi-stage pipeline —— we need to put the final output into the SVM and then the regressor. Fast RCNN is born to handle the preblem. The trait of Fast RCNN is single-stage and multi-task. The schemetic diagram is below:</p><p><img src="Picture16.png" alt=""></p><p>They use softmax to replace SVM because they find softmax is litter better than SVM in this task. We find that all tasks is compressed into one network. </p><p>Another change is that they replace the spatial pyramid pooling layer with a ROI pooling layer(ROI : region of interest) which is a simplified version of SPP. They only use one scale like 7 <em> 7 instead of 4 </em> 4 + 2 * 2 + 1 because they experimented to find that complication brings no improvement.</p><h2 id="Faster-RCNN"><a href="#Faster-RCNN" class="headerlink" title="Faster RCNN"></a>Faster RCNN</h2><p>The whole growing histroy we can summarize as a process of group all task into one single network. Faster RCNN contributes to moving the generate regions precess to the network where we call it RPN (Region Proposal Network). The overall proceeding is like this:</p><p><img src="Picture7.png" alt=""></p><p>The detailed schemetic diagram is like this:</p><p><img src="Picture8.png" alt=""></p><p>In order to generate appropriate proposals, we need to first define some fix-size and fix-location anchors by ourselves. we need to define different aspect ratio and different size so as to suit different object. The detail is like below:</p><p><img src="Picture9.png" alt=""><br><img src="Picture10.png" alt=""></p><p>We need to explain some place in the picture 2. As we all know, for one feature map and for one pixel, it has a receptive field. If we project a pixel in the feature map somewhere to the raw image. This will be an area which we call grid ceil. For one grid ceil, we define k anchors. In this paper, we consider k as 9 in default. 2k means that for k anchor, there will be two categories, whether it has a object or not. 4k’s 4 means (x, y, w, h) for every anchor.</p><p>Based on the explanation above, we can take a step forward. The detail RPN is like this:</p><p><img src="Picture11.png" alt=""></p><p>The network above is a classification layer. And the third dimension is eighteen filters which is 2 <em> 9(k), 36 is the 4 </em> 9(k). We send all of this into the proposal layer which we include sorting, NMS, and sorting and NMS again(NMS : non maximum supression).</p><h2 id="Mask-RCNN"><a href="#Mask-RCNN" class="headerlink" title="Mask RCNN"></a>Mask RCNN</h2><p>The main change to the Mask RCNN is below:</p><p><img src="Picture12.png" alt=""></p><p>The network add a Lmask task in the final network and replace the ROI pooling with the ROI Align network. The network itself is also improved<br>on the basis of the some methods called ResNeXt-101 and FPN.</p><p>ResNeXt-101 is an updated version of Resnet. The ResNet and ResNeXt-101’s structure is like below:</p><p><img src="Picture13.png" alt=""></p><p>ResNet is a network to solve the draback of deep convolutional network. When the convolutional network is becoming deeper, the accuracy become lower. Because the deeper layer has the responsibility of predict the truth. So we can use the method of boosting tree. For one layer, we only predict the residual of them. For example, we  have the input x, and output is F(x), and the truth is T. If we want to compare the F(x) and T, the pressure is huge. But instead we can use F(x) to compare to the T - x, then it’s easier.  ResNet is a example of this. ResNeXt-101 is an improvement of it. ResNeXt-101 is inspired by the neurons. As we all know, neural network has many neurons which play the role of learn the different feature independetly. So the ResNet-101 use the method of split-transform-merge. The total 32 parts play the different role.</p><p>FPN is born to handle the problem of difficulty of detecting small object. Suppose that a small object is 32 * 32, then if we have a network that has a smaller multiple of 32. Then the last feature map the object only has one pixel. In order to solve the problem, some papers like SSD use the method in the third picture. For the proceeding feature map, each has a predict value. But we know that for every feature map, it has the role of learning different semantics. Like the higher map learn the high semantics and the lower map learn the low semantics. It’s imappropriate to use different feature map to predict the result. So FPN(Feature pyramid network) change it. The lower feature map combine the trait of the higher feature map. But the upsample process has a lot of loss. So we need to use lateral connection —— combine the network before. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Detection is an important part of computer vision. Today I will take a view at the prevail algorithm in detection areas, named RCNN and i
      
    
    </summary>
    
      <category term="technology" scheme="http://yoursite.com/categories/technology/"/>
    
    
      <category term="CV" scheme="http://yoursite.com/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>yolo演变史</title>
    <link href="http://yoursite.com/2018/04/01/yolo%E6%BC%94%E5%8F%98%E5%8F%B2/"/>
    <id>http://yoursite.com/2018/04/01/yolo演变史/</id>
    <published>2018-04-01T12:14:26.000Z</published>
    <updated>2018-04-01T17:59:48.086Z</updated>
    
    <content type="html"><![CDATA[<h2 id="yolo-9000"><a href="#yolo-9000" class="headerlink" title="yolo 9000"></a>yolo 9000</h2><p>yolo suffers from a variety of shortcomings such as high localization loss and low recall compared to region proposal-based methods. So yolo mainly focus on improving recall and localization while maintaining classification accuracy.</p><p>yolo 9000 adopts some methods to better their model like:</p><ul><li><p>Batch Normalization: improve mAP, regularize the model, reduce the overfitting, and make weight initlization easier. 2% mAP</p></li><li><p>High Resolution Classifier: Unlike yolo, we first fine tune the classification network at the full 448*448 resolution and then the detection. </p></li><li><p>Using anchor box:  We know that yolo1 predicts the coordinates of bounding boxes directly using fully connected layers. While Faster RCNN predicts the offsets and confidences for anchor boxes using convolutional layers. So we adopt the anchor boxes method which predicts class and objectness for every anchor box. Note that this method wound be improved below.</p></li><li><p>Unlike Faster RCNN, we don’t use hand-picked priors. This means that we don’t define the width and hight manually but use k-means to learn the priors. We choose k = 5 as a tradeoff between model complexity and high recall. To avoid the imbalance between big boxes and small boxes, we redefine the disance matrix like : d = 1 - IOU(box, centroid). Here’s a code anaysis <a href="https://blog.csdn.net/hrsstudy/article/details/71173305" target="_blank" rel="noopener">k-means yolov2</a></p></li><li><p>Faster RCNN choose (tx, ty) to calculate the (x, y) like: </p><p>  x = (tx * w) - X</p><p>  y = (ty * w) - Y</p><p>  the model is instable because a anchor can end up at any location </p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;yolo-9000&quot;&gt;&lt;a href=&quot;#yolo-9000&quot; class=&quot;headerlink&quot; title=&quot;yolo 9000&quot;&gt;&lt;/a&gt;yolo 9000&lt;/h2&gt;&lt;p&gt;yolo suffers from a variety of shortcoming
      
    
    </summary>
    
      <category term="technology" scheme="http://yoursite.com/categories/technology/"/>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>CTC原理及代码解析</title>
    <link href="http://yoursite.com/2018/03/21/CTC%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    <id>http://yoursite.com/2018/03/21/CTC原理及代码解析/</id>
    <published>2018-03-21T14:51:21.000Z</published>
    <updated>2018-03-29T14:08:39.709Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>CTC经常使用于语音识别中，这次我们将基于RNN讲一讲它。</p><p>对语音进行识别的时候，一般需要把语音分成许多时间步，这样的话才能够有办法将其识别，比如：</p><pre><code>_bbee_ee___</code></pre><p>由于语音被拖长，bee这个词只能显示如上，其中还包括了空白(blank)，RNN中，我们把这个词的总时间步(time step)记为T, 而对于每个时间步长，它还有一个维度就是概率分布，假设字母表共有C个字母，则这个词语的维度就是C * T。</p><p>上面的例子是我们记录下来的形式，实际真实的标签(ground truth)应该是bee，肯定小于记录形式的长度。在这里，我需要对真实标签进行扩充。对于bee，我需要如下的表示:</p><pre><code>_b_e_e_</code></pre><p>对于这样一个中间的表示，我需要设它的长度为S，其原来真实标签的长度为L, 故有以下关系，S = 2L + 1。</p><p>接下来我们需要做的是前向计算（forward algorithm），其中还提到了动态规划（Dynamic Programing），了解了一下，不过比较迷，还未找到之间的联系。</p><p>这里我们假设对于RNN来说：其输出结果是[R1, R2, R3, R4], 而对于真实标签的中间状态G为[blank, g1, blank, g2, blank, g3, blank]。我们知道，R1只能对应blank或者g1, 而因此对于 t = 1, 我们有概率[P[0][1], P[1][1], 0, 0, 0, 0, 0]，对于t = 2, 我们有[0, (P[0][1] + P[1][1]) <em> P[1][2], P[1][1] </em> P[2][2], P[1][1] * P[3][2], 0, 0, 0], 以此类推。这实际上就是一种条件概率，根据前面的时间步的概率来计算下一个时间步的概率。从这一点来看，的确是借鉴了动态规划的思想就是将复杂的问题转化为一个个简单的子问题。</p><h1 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h1><p>其实根据前面的概率分析我们知道，输出结果对应真实标签的输出状态的概率分布是有一定规律的，从某个时刻开始某一项之前就不能再有对应项了，不然的话，输出就无法走不完全程，也就是无法对应全部真实标签，同理，在开始的时候，前几个输出项也不能对应G的后面几项。因此，我们设置start 和 end两个标准，所有对应只能在它们之间。下面是start 和 end 的计算方式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">int remain = (S / 2) + repeats - (T - t)</span><br><span class="line">if(remain &gt; 0)&#123;</span><br><span class="line">    start += s_inc[remain];</span><br><span class="line">&#125;</span><br><span class="line">if(t &lt;= (S / 2) + repeats)&#123;</span><br><span class="line">    end += e_inc[t - 1]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们先不看repeats, S / 2是真实标签的数量, 当 t = 0 的时候，remain应该是负数，当remain&gt;0的时候，意味着start不能待在开始，n = 1，意味着start需要到2处，n = 3，说明start需要到6处，以此类推，所以在不考虑repeats的情况下，每次start加2，而end同理。</p><p>但是我们必须考虑有repeats的情况，当真实标签中有重复比如bee的情况的时候，两个e之间的空白不能跳过，不然我们会认为只有一个e,因此start和end在遇到有重复的情况的时候，只能加一，加一这种状态必须出现两次。repeats每多一次，starts的增加就少一次，所以remai必须加上repeats以保证提前变为正数。由此，以上代码就解释的通了。</p><p>通过以上解释，数组的初始化也应该说得通了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">nt e_counter = 0;</span><br><span class="line">int s_counter = 0;</span><br><span class="line"></span><br><span class="line">s_inc[s_counter++] = 1;</span><br><span class="line"></span><br><span class="line">int repeats = 0;</span><br><span class="line"></span><br><span class="line">for (int i = 1; i &lt; L; ++i) &#123;</span><br><span class="line">    if (labels[i-1] == labels[i]) &#123;</span><br><span class="line">        s_inc[s_counter++] = 1;</span><br><span class="line">        s_inc[s_counter++] = 1;</span><br><span class="line">        e_inc[e_counter++] = 1;</span><br><span class="line">        e_inc[e_counter++] = 1;</span><br><span class="line">        ++repeats;</span><br><span class="line">    &#125;</span><br><span class="line">    else &#123;</span><br><span class="line">        s_inc[s_counter++] = 2;</span><br><span class="line">        e_inc[e_counter++] = 2;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">e_inc[e_counter++] = 1;</span><br></pre></td></tr></table></figure></p><h1 id="更新-2018-3-24"><a href="#更新-2018-3-24" class="headerlink" title="更新 2018.3.24"></a>更新 2018.3.24</h1><p>之前的是对CTC原理中动态规划部分的主要解释，今天我们来讲一讲它就是如何应用到RNN中去的。为了方便，我将采用CRNN模型，<a href="https://arxiv.org/abs/1507.05717" target="_blank" rel="noopener">论文地址</a>。</p><p>了解CRNN后知道，CRNN的输出是一个序列y = y1, y2, y3, … yT, 其中yt是一个字母表+空白的概率分布，我们定义π是y的其中一种情况(path)，定义一个函数(Sequqnce to Sequence)B，B(π)是产生一个标签(label)，比如B(–he–l-l–oo-)是hello，我们假设真实标签是l， 那么在训练的时候，我们首先需要求出输入在进入CTC之后，所产生的输出是l的概率，也就是条件概率。如图所示:</p><p><img src="math1.png" alt=""></p><p>根据这个概率，我们可以采用negative log-likelihood来计算损失函数，从而bp和optimize。这里面，p(π|y) = Π(yt(πt)),如果直接计算p(π|y)当然非常复杂，所以CTC采用了动态规划的思想，也就是我上面介绍的内容。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;CTC经常使用于语音识别中，这次我们将基于RNN讲一讲它。&lt;/p&gt;
&lt;p&gt;对语音进行识别的时候，一般需要把语音分成许多时间步，这样的话才能够
      
    
    </summary>
    
      <category term="technology" scheme="http://yoursite.com/categories/technology/"/>
    
    
      <category term="Machine Learning" scheme="http://yoursite.com/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>给自己的规矩</title>
    <link href="http://yoursite.com/2018/03/19/%E7%BB%99%E8%87%AA%E5%B7%B1%E7%9A%84%E8%A7%84%E7%9F%A9/"/>
    <id>http://yoursite.com/2018/03/19/给自己的规矩/</id>
    <published>2018-03-18T20:18:52.000Z</published>
    <updated>2018-03-18T20:28:19.412Z</updated>
    
    <content type="html"><![CDATA[<p>根据之前自己的文章《最近的想法》而制定的自己的一些规矩，希望自己能够一直坚持下去：</p><ul><li><p>手机不允许带到床上</p></li><li><p>晚上没课去图书馆，回来去七楼，十一点下去学英语和一些杂事。</p></li><li><p>每天写daily report, 每周写weekly report</p></li><li><p>一周一篇论文，需要完全读懂。</p></li><li><p>十二点一定要上床。</p></li><li><p>不允许带耳机出门。</p></li></ul><p>写下来以便时刻提醒监督自己。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;根据之前自己的文章《最近的想法》而制定的自己的一些规矩，希望自己能够一直坚持下去：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;手机不允许带到床上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;晚上没课去图书馆，回来去七楼，十一点下去学英语和一些杂事。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;每天写da
      
    
    </summary>
    
      <category term="life" scheme="http://yoursite.com/categories/life/"/>
    
    
      <category term="日记" scheme="http://yoursite.com/tags/%E6%97%A5%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Evaluation Standard</title>
    <link href="http://yoursite.com/2018/03/10/Evaluation-Standard/"/>
    <id>http://yoursite.com/2018/03/10/Evaluation-Standard/</id>
    <published>2018-03-10T11:01:50.000Z</published>
    <updated>2018-03-15T19:11:33.655Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Evaluation-Standard"><a href="#Evaluation-Standard" class="headerlink" title="Evaluation Standard"></a>Evaluation Standard</h1><h3 id="Accurency-Precision-Recall-F1-ROC-AUC"><a href="#Accurency-Precision-Recall-F1-ROC-AUC" class="headerlink" title="Accurency/Precision/Recall/F1/ROC/AUC"></a>Accurency/Precision/Recall/F1/ROC/AUC</h3><h2 id="Accurency"><a href="#Accurency" class="headerlink" title="Accurency"></a>Accurency</h2><p>accurency = right / all (right: the instance you predict right, all； all sample)</p><h2 id="Precision-and-Recall-and-F1"><a href="#Precision-and-Recall-and-F1" class="headerlink" title="Precision and Recall and F1"></a>Precision and Recall and F1</h2><h3 id="1-confusion-matrix"><a href="#1-confusion-matrix" class="headerlink" title="1. confusion matrix"></a>1. confusion matrix</h3><p>TP: true positive   FN: false negative</p><p>FP: false positive   TP: True negative</p><h3 id="2-Precision"><a href="#2-Precision" class="headerlink" title="2. Precision"></a>2. Precision</h3><p>P = TP/(TP + FP)</p><p>It refers to the accurency rate of you prediction</p><h3 id="3-Recall"><a href="#3-Recall" class="headerlink" title="3. Recall"></a>3. Recall</h3><p>R = TP/(TP + FN)</p><p>It refers to the comprehensive rate of your prediction</p><h3 id="4-Precision-and-Recall’s-description"><a href="#4-Precision-and-Recall’s-description" class="headerlink" title="4. Precision and Recall’s description"></a>4. Precision and Recall’s description</h3><p>The Precision and Recall are often in conflict with each other, so if one P-R curve is completely wrapped by another, then we can assume that the latter is better.</p><h3 id="5-F1"><a href="#5-F1" class="headerlink" title="5. F1"></a>5. F1</h3><p>F1 is the harmonic mean of the precision and recall</p><p>definition: F1 = (2 <em> P </em> R)/(P + R)</p><p>If we want to give a weight to the each evaluation method, then we can use the β like this</p><p>F1 = (1 + β^2) <em> P </em> R/((β^2 * P) + B)</p><h3 id="6-extension-and-application"><a href="#6-extension-and-application" class="headerlink" title="6. extension and application"></a>6. extension and application</h3><p>Sometimes we some other situation:</p><ul><li>have trained and tested quite a few times and we get severial confusion matrix  </li><li>have trained and tested in different datasets, hoping to evaluate the algorithm as a whole</li><li>for Multi-category tasks, we combine each two category into a confusion matrix</li></ul><p>one method:</p><p>calculate each Precision and Recall in different confusion matrix and then calculate the mean of them(called macro-P, macro-R and macro-F1)</p><p>macro-P = 1/n <em> ∑P<br>macro-R = 1/n </em> ∑R<br>macro-F1 = (2 <em> macro-P </em> macro-R)/(macro-P + macro-R)</p><p>another method:</p><p>calculate the mean of TP, FP, FN, TN, then calculate the micro-P, micro-R and micro-F1</p><h2 id="ROC-and-AUC"><a href="#ROC-and-AUC" class="headerlink" title="ROC and AUC"></a>ROC and AUC</h2><p>So many learning model generate a value or probablity prediction and then compare it with the threshold. Then we cansort the value and get a cut point and divide the sample into two part. So the quality of sorting represent the ability of generalization, anfd we can use the ROC curve</p><p><img src="ROC.png" alt=""></p><p>If we assume that one marker is (x, y), then if the next sample is the true positive, then the coordinate of it is (x, y + 1/m+), and if it is false positive, then the coordinate of it is (x + 1/m-, y)</p><p>Just like above, if one learning model’s ROC curve is wrapped by the another, then the latter is better. Another method to measure is to compare the <em>Areas Under the ROC Curve</em>(<strong>AUC</strong>)</p><p>defintion: AUC = 1/2 ∑(xi+1 - xi) <em> (yi + yi+1)   </em>i from 1 to m-1*</p><p>AUC is the evaluation of the quality of prediction sorting, if we have m+ positive example and m- negative example, and D+ and D- represent positive and negative set, then we can define loss as:</p><p>lrank = 1/m+ <em> m- ∑ ∑ (II(f(x+) &lt; f(x-)) + 1/2 </em> II(f(x+) = f(x-)))</p><p>This means that if the positive prediction value is smaller than the negative, then you are punished by one point, the same as another. We can find that AUC = 1 - lrank</p><h2 id="mAP"><a href="#mAP" class="headerlink" title="mAP"></a>mAP</h2><p>mAP is often used in computer vision which means “mean average precision”. Suppose that we have ten true objects and then we can have ten recall objects, for every recall target, we choose the maximum precision among the index of target and later target as the precision of this recall target. Then we calculate the average of them as the average precision(<strong>AP</strong>), that’s for two categories, if we have multiple categories. then for every category and other categories viewed as one category, we also adopt this method and calculate the means(<strong>mean average precision</strong>).</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Evaluation-Standard&quot;&gt;&lt;a href=&quot;#Evaluation-Standard&quot; class=&quot;headerlink&quot; title=&quot;Evaluation Standard&quot;&gt;&lt;/a&gt;Evaluation Standard&lt;/h1&gt;&lt;h3 i
      
    
    </summary>
    
      <category term="technology" scheme="http://yoursite.com/categories/technology/"/>
    
    
      <category term="Machine learning" scheme="http://yoursite.com/tags/Machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>读资本论</title>
    <link href="http://yoursite.com/2018/03/06/%E8%AF%BB%E8%B5%84%E6%9C%AC%E8%AE%BA/"/>
    <id>http://yoursite.com/2018/03/06/读资本论/</id>
    <published>2018-03-05T23:15:31.000Z</published>
    <updated>2018-03-05T23:18:26.603Z</updated>
    
    <content type="html"><![CDATA[<p>百忙之中偶有余闲，决定读一读《资本论》，权当兴趣使然。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;百忙之中偶有余闲，决定读一读《资本论》，权当兴趣使然。&lt;/p&gt;

      
    
    </summary>
    
      <category term="life" scheme="http://yoursite.com/categories/life/"/>
    
    
      <category term="经济" scheme="http://yoursite.com/tags/%E7%BB%8F%E6%B5%8E/"/>
    
  </entry>
  
  <entry>
    <title>Faster RCNN 详解与实现</title>
    <link href="http://yoursite.com/2018/02/26/Faster-RCNN-%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/"/>
    <id>http://yoursite.com/2018/02/26/Faster-RCNN-详解与实现/</id>
    <published>2018-02-25T16:54:50.000Z</published>
    <updated>2018-03-05T23:09:48.029Z</updated>
    
    <content type="html"><![CDATA[<p>最近一直在研究CV领域的一些算法，由于本人编程水平较弱加之faster rcnn算法比较复杂，虽然原理在很早就大致看懂，但在看源码的时候仍然吃了不少苦头，近些时候，终于了解了代码的大致含义并借鉴大神们的代码自己用pytorch实现了一下。在此，想跟大家详细地解释一下代码的含义， 帮助读者更好的理解这一算法。本人代码如下：</p><p><a href="https://github.com/starcraft2chunjie/Faster-RCNN-pytorch/tree/master" target="_blank" rel="noopener">Faster-RCNN-pytorch</a></p><p>需要先了解一下faster rcnn的读者可以点击以下链接，这是本人看到的比较全面细致的faster rcnn教程。</p><p><a href="https://www.jianshu.com/p/de37451a0a77?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation" target="_blank" rel="noopener">Faster RCNN 详解</a></p><h2 id="model"><a href="#model" class="headerlink" title="model"></a>model</h2><p>这一部分对应model_easy.py，我们知道, Faster RCNN 总共实际上就是四个模型，CNN模型， RPN(Region proposal layer), ROI Pooling layer, Classification layer(可以称为Faster RCNN层)。CNN层使用预训练的vgg16提取特征，得到feature map，然后进入RPN层, RPN层s首先经过一个kernel_size为3的层,之后再分为两部分，分别输出2<em>9大小和4</em>9大小的向量（对应于9 anchor <em> 2 classifier以及 9 anchor </em> 4 coordinate）,通过训练修正proposal的位置以及数量（通过rpn文件里面的proposal_layer.py），修正好的proposal进入ROI Pooling层统一划成7*7大小，最后进入FasterRCNN层输出最后的bbox_pred(bbox_delta)以及scores。</p><p>CNN层比较简单，在这里不再赘述。我们看一看RPN层的源码。</p><h3 id="RPN"><a href="#RPN" class="headerlink" title="RPN"></a>RPN</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"># the simple model of RPN</span><br><span class="line">class RPN(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(RPN, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.conv = nn.Sequential(nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=(1, 1)),</span><br><span class="line">                                            nn.ReLU())</span><br><span class="line"></span><br><span class="line">        # 9 anchor * 2 classfier (object or non-object) each grid</span><br><span class="line">        self.conv1 = nn.Conv2d(512, 2 * 9, kernel_size=1, stride=1)</span><br><span class="line"></span><br><span class="line">        # 9 anchor * 4 coordinate regressor each grids</span><br><span class="line">        self.conv2 = nn.Conv2d(512, 4 * 9, kernel_size=1, stride=1)</span><br><span class="line">        self.softmax = nn.Softmax()</span><br><span class="line"></span><br><span class="line">    def forward(self, features):</span><br><span class="line"></span><br><span class="line">        features = self.conv(features)</span><br><span class="line"></span><br><span class="line">        logits, rpn_bbox_pred = self.conv1(features), self.conv2(features)</span><br><span class="line"></span><br><span class="line">        height, width = features.size()[-2:]</span><br><span class="line">        logits = logits.squeeze(0).permute(1, 2, 0).contiguous()  # (1, 18, H/16, W/16) =&gt; (H/16 ,W/16, 18)</span><br><span class="line">        logits = logits.view(-1, 2)  # (H/16 ,W/16, 18) =&gt; (H/16 * W/16 * 9, 2)</span><br><span class="line"></span><br><span class="line">        rpn_cls_prob = self.softmax(logits)</span><br><span class="line">        rpn_cls_prob = rpn_cls_prob.view(height, width, 18)  # (H/16 * W/16 * 9, 2)  =&gt; (H/16 ,W/16, 18)</span><br><span class="line">        rpn_cls_prob = rpn_cls_prob.permute(2, 0, 1).contiguous().unsqueeze(0) # (H/16 ,W/16, 18) =&gt; (1, 18, H/16, W/16)</span><br><span class="line"></span><br><span class="line">        return rpn_bbox_pred, rpn_cls_prob, logits</span><br></pre></td></tr></table></figure><p>注意forward的返回值，一个是rpn_bbox_pred，这个是我们我提到的教程里面的预测的[dx, dy, dh, dw]，也是之后的bbox_delta。rpn_cls_prob也仅仅只是logits经过了一层softmax函数而已。模型大致架构比较简单，下面来看看与RPN层相关的函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">def proposal(self, rpn_bbox_pred, rpn_cls_prob, im_info, test, args):</span><br><span class="line">       &quot;&quot;&quot;</span><br><span class="line">       Arguments:</span><br><span class="line">           rpn_bbox_pred (Tensor) : (1, 4*9, H/16, W/16)</span><br><span class="line">           rpn_cls_prob (Tensor) : (1, 2*9, H/16, W/16)</span><br><span class="line">           im_info (Tuple) : (Height, Width, Channel, scale_ratios)</span><br><span class="line">           test (Bool) : True or False</span><br><span class="line">           args (argparse.Namespace) : global arguments</span><br><span class="line">       Return:</span><br><span class="line">           # in each minibatch number of proposal boxes is variable</span><br><span class="line">           proposals_boxes (Ndarray) : ( # proposal boxes, 4)</span><br><span class="line">           scores (Ndarray) :  ( # proposal boxes, )</span><br><span class="line">       &quot;&quot;&quot;</span><br><span class="line">       &quot;&quot;&quot;</span><br><span class="line">       # Algorithm:</span><br><span class="line">       #</span><br><span class="line">       # for each (H, W) location i</span><br><span class="line">       #   generate A anchor boxes centered on cell i</span><br><span class="line">       #   apply predicted bbox deltas at cell i to each of the A anchors</span><br><span class="line">       # clip predicted boxes to image</span><br><span class="line">       # remove predicted boxes with either height or width &lt; threshold</span><br><span class="line">       # sort all (proposal, score) pairs by score from highest to lowest</span><br><span class="line">       # take top pre_nms_topN proposals before NMS</span><br><span class="line">       # apply NMS with threshold 0.7 to remaining proposals</span><br><span class="line">       # take after_nms_topN proposals after NMS</span><br><span class="line">       # return the top proposals (-&gt; RoIs top, scores top)</span><br><span class="line">       #layer_params = yaml.load(self.param_str_)</span><br><span class="line">       &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       anchors = generate_anchors()</span><br><span class="line">       _num_anchors = anchors.shape[0]</span><br><span class="line"></span><br><span class="line">       all_anchors = get_anchor(rpn_cls_prob, anchors)   # [H * W * 9, 4]</span><br><span class="line"></span><br><span class="line">       pre_nms_topn = args.pre_nms_topn if test == False else args.test_pre_nms_topn</span><br><span class="line">       nms_thresh = args.nms_thresh if test == False else args.test_nms_thresh</span><br><span class="line">       post_nms_topn = args.post_nms_topn if test == False else args.test_post_nms_topn</span><br><span class="line"></span><br><span class="line">       &quot;&quot;&quot;It&apos;s directly from anchor_target_layer, essentially from training the RPN&quot;&quot;&quot;</span><br><span class="line">       bbox_deltas = self._get_bbox_deltas(rpn_bbox_pred).data.cpu().numpy()</span><br><span class="line"></span><br><span class="line">       # 1. Convert anchors into proposal via bbox transformation</span><br><span class="line">       &quot;&quot;&quot;Here we need to generate the precise proposal location for the later operation&quot;&quot;&quot;</span><br><span class="line">       proposals_boxes = bbox_transform_inv(all_anchors, bbox_deltas)  # (H/16 * W/16 * 9, 4) all proposal boxes</span><br><span class="line">       scores = self._get_pos_score(rpn_cls_prob).data.cpu().numpy()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       # 2. clip predicted boxes to image</span><br><span class="line">       proposals = clip_boxes(proposals_boxes, im_info[:2])</span><br><span class="line"></span><br><span class="line">        # 3. remove predicted boxes with either height or width &lt; threshold</span><br><span class="line">       # (NOTE: convert min_size to input image scale stored in im_info[3])</span><br><span class="line">       keep = filter_boxes(proposals_boxes, self.args.min_size * max(im_info[3]))</span><br><span class="line">       proposals = proposals[keep, :]</span><br><span class="line">       scores = scores[keep]</span><br><span class="line"></span><br><span class="line">       # 4. sort all (proposal, score) pairs by score from highest to lowest</span><br><span class="line">       # 5. take top pre_nms_topn (e.g. 6000)</span><br><span class="line">       order = scores.ravel().argsort()[::-1]</span><br><span class="line">       if pre_nms_topn &gt; 0:</span><br><span class="line">           order = order[:pre_nms_topn]</span><br><span class="line">       proposals = proposals[order, :]</span><br><span class="line">       scores = scores[order]</span><br><span class="line"></span><br><span class="line">       # 6. apply nms (e.g. threshold = 0.7)</span><br><span class="line"></span><br><span class="line">       keep = py_cpu_nms(np.hstack((proposals, scores)), nms_thresh)</span><br><span class="line"></span><br><span class="line">       # 7. take after_nms_topN (e.g. 300)</span><br><span class="line">       if post_nms_topn &gt; 0:</span><br><span class="line">           keep = keep[:post_nms_topn]</span><br><span class="line">       </span><br><span class="line">       # 8. return the top proposals (-&gt; RoIs top)</span><br><span class="line">       proposals = proposals[keep, :]</span><br><span class="line">       scores = scores[keep]</span><br><span class="line">       batch_inds = np.zeros((proposals.shape[0], 1), dtype=np.float32)</span><br><span class="line">       blob = np.hstack((batch_inds, proposals.astype(np.float32, copy = False)))</span><br><span class="line">       return blob</span><br></pre></td></tr></table></figure><p>这段代码的作用是什么？用教程里面的话就是：</p><blockquote><ol><li>生成anchors，利用[dx(A)，dy(A)，dw(A)，dh(A)]对所有的anchors做bbox regression回归（这里的anchors生成和训练时完全一致）</li></ol></blockquote><blockquote><ol><li>按照输入的foreground softmax scores由大到小排序anchors，提取前pre_nms_topN(e.g. 6000)个anchors，即提取修正位置后的foreground anchors。</li></ol></blockquote><blockquote><ol><li>利用im_info将fg anchors从MxN尺度映射回PxQ原图，判断fg anchors是否大范围超过边界，剔除严重超出边界fg anchors。</li></ol></blockquote><blockquote><ol><li>进行nms（nonmaximum suppression，非极大值抑制）</li></ol></blockquote><blockquote><ol><li>再次按照nms后的foreground softmax scores由大到小排序fg anchors，提取前post_nms_topN(e.g. 300)结果作为proposal输出。</li></ol></blockquote><blockquote><ol><li>之后输出proposal=[x1, y1, x2, y2]，注意，由于在第三步中将anchors映射回原图判断是否超出边界，所以这里输出的proposal是对应MxN输入图像尺度的</li></ol></blockquote><p>简单来说，就是对产生的所有anchor进行修正以及筛选。此函数输入的主要参数是之前RPN网络输出的rpn_bbox_pred以及rpn_cls_prob。这里有几行代码需要解释一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bbox_deltas = self._get_bbox_deltas(rpn_bbox_pred).data.cpu().numpy()</span><br><span class="line"></span><br><span class="line">proposals_boxes = bbox_transform_inv(all_anchors, bbox_deltas)  # (H/16 * W/16 * 9, 4) all proposal boxes</span><br><span class="line"></span><br><span class="line">scores = self._get_pos_score(rpn_cls_prob).data.cpu().numpy()</span><br></pre></td></tr></table></figure><p>_get_bbox_deltas仅仅是把rpn_bbox_pred转换为了（H/16 <em> W/16 </em> 9, 4）, bbox_transform_inv则是根据bbox_deltas以及anchors生成了对应的pred_anchor(注意之前的rpn_bbox_pred仅仅是生成的[dx, dy, dh, dw]，不是最终确定的proposal)，_get_pos_score也仅仅是将rpn_cls_score转化为(H/16 <em> W/16 </em> 9, 1)</p><h3 id="ROI-Pooling"><a href="#ROI-Pooling" class="headerlink" title="ROI Pooling"></a>ROI Pooling</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">class ROIpooling(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, size=(7, 7), spatial_scale=1.0 / 16.0):</span><br><span class="line">        super(ROIpooling, self).__init__()</span><br><span class="line">        self.adapmax2d = nn.AdaptiveMaxPool2d(size)</span><br><span class="line">        self.spatial_scale = spatial_scale</span><br><span class="line"></span><br><span class="line">    def forward(self, features, rois_boxes):</span><br><span class="line"></span><br><span class="line">        # rois_boxes : [x, y, x`, y`]</span><br><span class="line"></span><br><span class="line">        if type(rois_boxes) == np.ndarray:</span><br><span class="line">            rois_boxes = to_var(torch.from_numpy(rois_boxes))</span><br><span class="line"></span><br><span class="line">        rois_boxes = rois_boxes.data.float().clone()</span><br><span class="line">        rois_boxes.mul_(self.spatial_scale)</span><br><span class="line">        rois_boxes = rois_boxes.long()</span><br><span class="line"></span><br><span class="line">        output = []</span><br><span class="line"></span><br><span class="line">        for i in range(rois_boxes.size(0)):</span><br><span class="line">            roi = rois_boxes[i]</span><br><span class="line"></span><br><span class="line">            try:</span><br><span class="line"></span><br><span class="line">                roi_feature = features[:, :, roi[1]:(roi[3] + 1), roi[0]:(roi[2] + 1)]</span><br><span class="line">            except Exception as e:</span><br><span class="line">                print(e, roi)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            pool_feature = self.adapmax2d(roi_feature)</span><br><span class="line">            output.append(pool_feature)</span><br><span class="line"></span><br><span class="line">        return torch.cat(output, 0)</span><br></pre></td></tr></table></figure><p>ROI Pooling显得比较简单，但这并不是因为其算法本身简单，实际上，此层需要实现的算法是对任意输入的proposal，都要加工成7*7大小，这个工作量似乎不小，实际上，之前大神的代码里，ROI Pooling的实现代码很长，但正因为如此，pytorch的contributor将其封装，现在仅仅只需要调用adapmax2d就可以了。</p><h3 id="FasterRCNN"><a href="#FasterRCNN" class="headerlink" title="FasterRCNN"></a>FasterRCNN</h3><p>这个代码比较简单，没什么好讲的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">class FasterRcnn(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(FasterRcnn, self).__init__()</span><br><span class="line">        self.fc1 = nn.Sequential(nn.Linear(512 * 7 * 7, 4096),</span><br><span class="line">                                 nn.ReLU(),</span><br><span class="line">                                 nn.Dropout())</span><br><span class="line"></span><br><span class="line">        self.fc2 = nn.Sequential(nn.Linear(4096, 4096),</span><br><span class="line">                                 nn.ReLU(),</span><br><span class="line">                                 nn.Dropout())</span><br><span class="line"></span><br><span class="line">        # 20 class + 1 backround classfier each roi</span><br><span class="line">        self.classfier = nn.Linear(4096, 21)</span><br><span class="line">        self.softmax = nn.Softmax()</span><br><span class="line"></span><br><span class="line">        # 21 class * 4 coordinate regressor each roi</span><br><span class="line">        self.regressor = nn.Linear(4096, 21 * 4)</span><br><span class="line"></span><br><span class="line">    def forward(self, features):</span><br><span class="line"></span><br><span class="line">        features = features.view(-1, 512 * 7 * 7)</span><br><span class="line">        features = self.fc1(features)</span><br><span class="line">        features = self.fc2(features)</span><br><span class="line"></span><br><span class="line">        try:</span><br><span class="line">            logits = self.classfier(features)</span><br><span class="line">            scores = self.softmax(logits)</span><br><span class="line">            bbox_delta = self.regressor(features)</span><br><span class="line"></span><br><span class="line">        except Exception as e:</span><br><span class="line">            print(e, logits)</span><br><span class="line"></span><br><span class="line">        return bbox_delta, scores, logits</span><br></pre></td></tr></table></figure><h2 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h2><p>loss部分主要分为两个部分，rpn_loss以及fasterRCNN_loss</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">def rpn_loss(rpn_cls_prob, rpn_logits, rpn_bbox_pred, rpn_labels, rpn_bbox_targets, rpn_bbox_inside_weights):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Arguments:</span><br><span class="line">        rpn_cls_prob (Tensor): (1, 2*9, H/16, W/16)</span><br><span class="line">        rpn_logits (Tensor): (H/16 * W/16 * 9 , 2) object or non-object rpn_logits</span><br><span class="line">        rpn_bbox_pred (Tensor): (1, 4*9, H/16, W/16) predicted boxes</span><br><span class="line">        rpn_labels (Ndarray) : (H/16 * W/16 * 9 ,)</span><br><span class="line">        rpn_bbox_targets (Ndarray) : (H/16 * W/16 * 9, 4)</span><br><span class="line">        rpn_bbox_inside_weights (Ndarray) : (H/16 * W/16 * 9, 4) masking for only positive box loss</span><br><span class="line">    Return:</span><br><span class="line">        cls_loss (Scalar) : classfication loss</span><br><span class="line">        reg_loss * 10 (Scalar) : regression loss</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    height, width = rpn_cls_prob.size()[-2:]  # (H/16, W/16)</span><br><span class="line">    rpn_cls_prob = rpn_cls_prob.squeeze(0).permute(1, 2, 0).contiguous()  # (1, 18, H/16, W/16) =&gt; (H/16 ,W/16, 18)</span><br><span class="line">    rpn_cls_prob = rpn_cls_prob.view(-1, 2)  # (H/16 ,W/16, 18) =&gt; (H/16 * W/16 * 9, 2)</span><br><span class="line"></span><br><span class="line">    rpn_labels = to_tensor(rpn_labels).long() # convert properly # (H/16 * W/16 * 9)</span><br><span class="line"></span><br><span class="line">    #index where not -1</span><br><span class="line">    idx = rpn_labels.ge(0).nonzero()[:, 0]</span><br><span class="line">    rpn_cls_prob = rpn_cls_prob.index_select(0, to_var(idx))</span><br><span class="line">    rpn_labels = rpn_labels.index_select(0, idx)</span><br><span class="line">    rpn_logits = rpn_logits.squeeze().index_select(0, to_var(idx))</span><br><span class="line"></span><br><span class="line">    positive_cnt = torch.sum(rpn_labels.eq(1))</span><br><span class="line">    negative_cnt = torch.sum(rpn_labels.eq(0))</span><br><span class="line"></span><br><span class="line">    rpn_labels = to_var(rpn_labels)</span><br><span class="line"></span><br><span class="line">    cls_crit = nn.CrossEntropyLoss()</span><br><span class="line">    cls_loss = cls_crit(rpn_logits, rpn_labels)</span><br><span class="line"></span><br><span class="line">    rpn_bbox_targets = torch.from_numpy(rpn_bbox_targets)</span><br><span class="line">    rpn_bbox_targets = rpn_bbox_targets.view(height, width, 36)  # (H/16 * W/16 * 9, 4)  =&gt; (H/16 ,W/16, 36)</span><br><span class="line">    rpn_bbox_targets = rpn_bbox_targets.permute(2, 0, 1).contiguous().unsqueeze(0) # (H/16 ,W/16, 36) =&gt; (1, 36, H/16, W/16)</span><br><span class="line">    rpn_bbox_targets = to_var(rpn_bbox_targets)</span><br><span class="line"></span><br><span class="line">    rpn_bbox_inside_weights = torch.from_numpy(rpn_bbox_inside_weights)</span><br><span class="line">    rpn_bbox_inside_weights = rpn_bbox_inside_weights.view(height, width, 36)  # (H/16 * W/16 * 9, 4)  =&gt; (H/16 ,W/16, 36)</span><br><span class="line">    rpn_bbox_inside_weights = rpn_bbox_inside_weights.permute(2, 0, 1).contiguous().unsqueeze(0) # (H/16 ,W/16, 36) =&gt; (1, 36, H/16, W/16)</span><br><span class="line"></span><br><span class="line">    rpn_bbox_inside_weights = rpn_bbox_inside_weights.cuda() if torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line">    rpn_bbox_pred = to_var(torch.mul(rpn_bbox_pred.data, rpn_bbox_inside_weights))</span><br><span class="line">    rpn_bbox_targets = to_var(torch.mul(rpn_bbox_targets.data, rpn_bbox_inside_weights))</span><br><span class="line"></span><br><span class="line">    reg_loss = F.smooth_l1_loss(rpn_bbox_pred, rpn_bbox_targets, size_average = False) / (positive_cnt + 1e-4)</span><br><span class="line"></span><br><span class="line">    return cls_loss, reg_loss * 10</span><br></pre></td></tr></table></figure><p>首先注意一点，rpn_bbox_targets, rpn_bbox_inside_weights这两个参数是从anchor_target此函数得来的。</p><p>rpn_loss的主要操作流程如下：</p><ul><li><p>筛选出label值不是-1的proposal(-1表示don’t care area)</p></li><li><p>计算出是前景的proposal和是背景的proposal的数目。</p></li><li><p>classification使用CrossEntropyLoss(注意CrossEntropyLoss已经包含了log softmaxLoss,所以只需要使用logits作为参数)</p></li><li><p>regression使用smooth_l1_loss</p></li><li><p>综合两个函数</p></li></ul><p>frcnn_loss与之相近，就不再赘述</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近一直在研究CV领域的一些算法，由于本人编程水平较弱加之faster rcnn算法比较复杂，虽然原理在很早就大致看懂，但在看源码的时候仍然吃了不少苦头，近些时候，终于了解了代码的大致含义并借鉴大神们的代码自己用pytorch实现了一下。在此，想跟大家详细地解释一下代码的含
      
    
    </summary>
    
      <category term="technology" scheme="http://yoursite.com/categories/technology/"/>
    
    
      <category term="CV" scheme="http://yoursite.com/tags/CV/"/>
    
  </entry>
  
</feed>
